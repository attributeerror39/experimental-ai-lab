{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbcfd12e-e56b-4f1d-92e8-456d3b3191c8",
   "metadata": {},
   "source": [
    "# Dataset: Ten Thousand Dreams\n",
    "\n",
    "The dataset we will create contains descriptions of dreams and their interpretations from Gustavus Hindman Miller's \"Ten Thousand Dreams, Interpreted.\"\n",
    "\n",
    "It's inspired by Allison Parrish's work \"I Waded In Clear Water\". https://github.com/aparrish/nanogenmo2014\n",
    "\n",
    "For her work, she prepared the data as following\n",
    "\n",
    ">  Each word has multiple interpretations, and most of these interpretations can be broken down into what I call an action and a denotation:\n",
    ">\n",
    "> To see an oak full of acorns, denotes increase and promotion.\n",
    ">\n",
    "> In this entry, See an oak full of acorns is the action, and increase and promotion is the denotation. The text of this novel was made by extracting the actions and changing them to first-person, past-tense sentences:\n",
    ">\n",
    "> I saw an oak full of acorns.\n",
    "\n",
    "Our final dataset will look like this:\n",
    "\n",
    "```\n",
    "{'conversations': [{'role': 'user', 'content': 'I saw an oak full of acorns.'},\n",
    "  {'role': 'assistant',\n",
    "   'content': 'To see an oak full of acorns, denotes increase and promotion. \\n'}]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c71261-55ea-455a-bc5d-55be3ae0fc5c",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "Probably the easiest way to get the data is to work with Parrish's code. It was written with Python 2 and uses a library that works only with Python 2, so we have to create a specific environment for that.\n",
    "\n",
    "```\n",
    "conda create -n datadreams python=2.7\n",
    "```\n",
    "\n",
    "Manually install pattern: https://digiasset.org/html/pattern.html\n",
    "\n",
    "Modiefied code, that reads the text from Gustavus Hindman Miller and returns a text file with lines like:\n",
    "\n",
    "> I saw a forest of oaks.|To dream of seeing a forest of oaks, signifies great prosperity in all conditions of life.\n",
    "> \n",
    "> I saw an oak full of acorns.|To see an oak full of acorns, denotes increase and promotion.\n",
    "\n",
    "\n",
    "```python\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "\n",
    "from pattern.en import parsetree, Word, conjugate, PAST, sentiment\n",
    "from pattern.search import search\n",
    "\n",
    "# from elaborate import elaborate_on, ElaborationImpossible\n",
    "# from badwords import is_blacklisted\n",
    "\n",
    "def phrase_replace(phrase):\n",
    "\toutput = [\"I\", conjugate(phrase[0].lemma, tense=PAST)]\n",
    "\tfor word in phrase[1:]:\n",
    "\t\tif word.string == 'you' and word.chunk.role == 'SBJ':\n",
    "\t\t\toutput.append('I')\n",
    "\t\telif word.string == 'you':\n",
    "\t\t\toutput.append('me')\n",
    "\t\telif word.string == 'her' and word.type == 'PRP$':\n",
    "\t\t\toutput.append('my')\n",
    "\t\telif word.string == 'her' and word.type == 'PRP':\n",
    "\t\t\toutput.append('me')\n",
    "\t\telif word.string in ('him', 'her') and word.chunk.role == 'OBJ':\n",
    "\t\t\toutput.append('me')\n",
    "\t\telif word.string in ('he', 'she') and word.chunk.role == 'SBJ':\n",
    "\t\t\toutput.append('I')\n",
    "\t\telif word.string == 'her':\n",
    "\t\t\toutput.append('my')\n",
    "\t\telif word.string == 'his':\n",
    "\t\t\toutput.append('my')\n",
    "\t\telif word.string == 'your':\n",
    "\t\t\toutput.append('my')\n",
    "\t\telif word.string in ('yourself', 'herself', 'himself'):\n",
    "\t\t\toutput.append('myself')\n",
    "\t\telif word.string in ('hers', 'yours'):\n",
    "\t\t\toutput.append('mine')\n",
    "\t\telif word.type in ('VBP', 'VBZ'):\n",
    "\t\t\toutput.append(conjugate(word.string, tense=PAST))\n",
    "\t\telse:\n",
    "\t\t\toutput.append(word.string)\n",
    "\toutput_str = ' '.join(output)\n",
    "\toutput_str = output_str.replace(\"caed n't\", \"couldn't\")\n",
    "\toutput_str = output_str.replace(\"thought me was\", \"thought I was\")\n",
    "\treturn output_str\n",
    "\n",
    "def extract_verb_phrases(tree):\n",
    "\tverb_phrase_matches = search('to|you {VP}', tree)\n",
    "\tphrases = list()\n",
    "\tif len(verb_phrase_matches) > 0:\n",
    "\t\tpossible_matches = list()\n",
    "\t\tfor match in verb_phrase_matches:\n",
    "\t\t\tif match.group(1)[0].string == \"dream\":\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tphrases.append(tree[match.group(1).start:])\n",
    "\treturn phrases\n",
    "\n",
    "def extract_verbs(tree):\n",
    "\tverb_matches = search('to|you {VB*}', tree)\n",
    "\tphrases = list()\n",
    "\tfor match in verb_matches:\n",
    "\t\tif match.group(1)[0].type in ('VBG', 'VBZ'): continue\n",
    "\t\tif match.group(1)[0].string == \"dream\": continue\n",
    "\t\tphrases.append(tree[match.group(1).start:])\n",
    "\treturn phrases\n",
    "\n",
    "def extract_to_dream_that(tree):\n",
    "\tmatches = search('to dream that she|he {VB*}', tree)\n",
    "\tphrases = list()\n",
    "\tfor match in matches:\n",
    "\t\tphrases.append(tree[match.group(1).start:])\n",
    "\treturn phrases\n",
    "\n",
    "def extract_gerunds(tree):\n",
    "\tmatches = search('to dream of {VBG}', tree)\n",
    "\tphrases = list()\n",
    "\tfor match in matches:\n",
    "\t\tphrases.append(tree[match.group(1).start:])\n",
    "\treturn phrases\n",
    "\n",
    "phrase_scores = list()\n",
    "para = \"\"\n",
    "output = []\n",
    "with open('data/dreams.txt', 'r') as f:\n",
    "\ttxt = f.readlines()\n",
    "\n",
    "for line in txt:\n",
    "\tline = line.strip()\n",
    "\tif line != \"\":\n",
    "\t\tpara += line + \" \"\n",
    "\telse:\n",
    "\t\t#print para\n",
    "\t\t#print parsetree(para)\n",
    "\t\t#print \"------\"\n",
    "\t\t# print para\n",
    "\t\tparts = re.split(r'\\s*[,;]\\s*', para)\n",
    "\t\tif len(parts) > 1 and not(parts[0].startswith('[')) and not('.' in parts[0]):\n",
    "\t\t\taction = parts[0]\n",
    "\t\t\tdenotes = ' '.join(parts[1:])\n",
    "\t\t\t#action = re.sub(r\"^to dream (that)?\", \"\", action, count=0, flags=re.I)\n",
    "\t\t\taction = re.sub(r\"in (your |a )?dreams?\", \"\", action)\n",
    "\t\t\taction = re.sub(r\"while dreaming\", \"\", action)\n",
    "\t\t\taction = re.sub(r\"\\{[^}]*\\}\", \"\", action)\n",
    "\t\t\t#print action\n",
    "\t\t\ttree = parsetree(action, lemmata=True, relations=True)[0]\n",
    "\t\t\t#print tree\n",
    "\t\t\tverb_phrases = extract_verb_phrases(tree)\n",
    "\t\t\t#print \"verb phrases: \" + str(verb_phrases)\n",
    "\t\t\tverbs = extract_verbs(tree)\n",
    "\t\t\t#print \"verbs: \" + str(verbs)\n",
    "\t\t\tdream_thats = extract_to_dream_that(tree)\n",
    "\t\t\t#print \"dream thats: \" + str(dream_thats)\n",
    "\t\t\tgerunds = extract_gerunds(tree)\n",
    "\t\t\t#print \"gerunds: \" + str(gerunds)\n",
    "\t\t\tphrases = set()\n",
    "\t\t\tfor phrase in verb_phrases + verbs + dream_thats + gerunds:\n",
    "\t\t\t\tphrases.add(phrase_replace(phrase) + \".\")\n",
    "\t\t\t#print phrases\n",
    "\t\t\tfor phrase in phrases:\n",
    "\t\t\t\t# if not(is_blacklisted(phrase)):\n",
    "\t\t\t\t# \tphrase_scores.append((phrase, int(sentiment(denotes)[0]*10), denotes))\n",
    "\t\t\t\tprint phrase + '|' + para\n",
    "\t\t\t\toutput.append(phrase + '|' + para)\n",
    "\t\t\t# print '|'\n",
    "\t\t\t# print para\n",
    "\t\tpara = \"\"\n",
    "\n",
    "with open('data/dreams_pairs.txt', 'w') as f:\n",
    "\tf.write('\\n'.join(output))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6408c16-a87e-4742-b340-32bcf48257e0",
   "metadata": {},
   "source": [
    "## Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dabff81-5881-471a-82d8-a84cfb47a2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was abandoned.|To dream that you are abandoned, denotes that you will have difficulty in framing your plans for future success. \n",
      "\n",
      "I abandoned others.|To abandon others, you will see unhappy conditions piled thick around you, leaving little hope of surmounting them. \n",
      "\n",
      "I abandoned.|If it is your house that you abandon, you will soon come to grief in experimenting with fortune. \n",
      "\n",
      "I abandoned my sweetheart.|If you abandon your sweetheart, you will fail to recover lost valuables, and friends will turn aside from your favors. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/dreams_pairs.txt') as f:\n",
    "    txt = f.readlines()\n",
    "\n",
    "for line in txt[:4]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0546b139-d9bc-4047-9e7c-7d12058a8864",
   "metadata": {},
   "source": [
    "To use this data for training a chatbot, we have to transform it into a specific form:\n",
    "\n",
    "```\n",
    "{'conversations': [{'role': 'user', 'content': 'I saw an oak full of acorns..'},\n",
    "  {'role': 'assistant',\n",
    "   'content': 'To see an oak full of acorns, denotes increase and promotion. \\n'}]}\n",
    "```\n",
    "\n",
    "Then we will create a list of all of these dictionaries. (So we'll have a list of dictionaries, which store a list of dictionaries.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b87c657b-588c-422d-b4b3-fab062b30467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_dict(user, assistant):\n",
    "    # create a list with the entries as dictionaries\n",
    "    conversation_data = [{'role':'user', 'content':user}, {'role':'assistant', 'content':assistant}]\n",
    "    # create a dictionary with key 'conversations' and add the list as value\n",
    "    dictionary = {'conversations':conversation_data}\n",
    "    return dictionary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98f3484a-b12e-4a9c-967d-b5f45ad88101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was abandoned.|To dream that you are abandoned, denotes that you will have difficulty in framing your plans for future success. \n",
      "\n",
      "I was abandoned.\n",
      "To dream that you are abandoned, denotes that you will have difficulty in framing your plans for future success.\n"
     ]
    }
   ],
   "source": [
    "line = txt[0]\n",
    "print(line)\n",
    "user, assistant = line.strip().split('|')  # Split a line into the text of user and assistant\n",
    "print(user)\n",
    "print(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48f323f6-d6d2-49bf-bcf3-dfe87e8e2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for line in txt:\n",
    "    # split into user and assistant\n",
    "    user, assistant = line.strip().split('|')\n",
    "    data = str_to_dict(user, assistant)\n",
    "    dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3696b566-26fe-4ab6-82ad-9a9329be30ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations': [{'role': 'user', 'content': 'I was abandoned.'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'To dream that you are abandoned, denotes that you will have difficulty in framing your plans for future success.'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c7b75f3-d3a1-4fac-9e63-2c2b15ee5843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3324"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7547a55c-26aa-4a9d-9681-67f1b138cb3d",
   "metadata": {},
   "source": [
    "## Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de4fbb21-e7d6-4b8d-bae6-0658257005ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/dreams.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08282707-17b5-4656-a6f9-d84abfb7c46a",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c836859-4fe8-4aff-8649-bc24d67a337b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.10.8)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.30.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad79621f-c114-42bb-aecf-bbb1af197ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3950a78ebcdd4a76a327ed5ac49b7678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset  # https://huggingface.co/docs/datasets/loading\n",
    "dataset = load_dataset('json', data_files='data/dreams.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81b372ed-2a71-414a-8fda-d91925093fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversations'],\n",
       "        num_rows: 3324\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b82efea-646d-4a18-aeeb-d272a01f613a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'I was abandoned.', 'role': 'user'},\n",
       " {'content': 'To dream that you are abandoned, denotes that you will have difficulty in framing your plans for future success.',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['conversations']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
